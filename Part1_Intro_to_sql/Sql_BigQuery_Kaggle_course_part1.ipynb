{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sql_BigQuery_Kaggle_course_part1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"jks8tTYKEV46","colab_type":"code","colab":{}},"source":["from google.cloud import bigquery"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jzrBS-DCE6dL","colab_type":"code","colab":{}},"source":["# Create a \"Client\" object\n","client = bigquery.Client()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HgHoT-bZHLye","colab_type":"code","colab":{}},"source":["# Construct a reference to the \"hacker_news\" dataset, in BigQuery, each dataset is contained in a corresponding project\n","dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n","\n","# API request - fetch the dataset\n","dataset = client.get_dataset(dataset_ref)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tsZIc0EkHNSA","colab_type":"code","colab":{}},"source":["# List all the tables in the \"hacker_news\" dataset\n","tables = list(client.list_tables(dataset))\n","\n","# Print names of all tables in the dataset (there are four!)\n","for table in tables:  \n","    print(table.table_id)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O6Fw0uZGHu3_","colab_type":"text"},"source":["Similar to how we fetched a dataset, we can fetch a table. In the code cell below, we fetch the full table in the hacker_news dataset."]},{"cell_type":"code","metadata":{"id":"PIO1hTu7HndM","colab_type":"code","colab":{}},"source":["# Construct a reference to the \"full\" table\n","table_ref = dataset_ref.table(\"full\")\n","\n","# API request - fetch the table\n","table = client.get_table(table_ref)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5p-_qkjIJJYC","colab_type":"text"},"source":["![](https://drive.google.com/uc?id=1UY7c-6Nz2ss2V93rLwlPcod_JIL9zmv4)"]},{"cell_type":"markdown","metadata":{"id":"RNZ9y6raKDcy","colab_type":"text"},"source":["#Table schema\n","\n","The structure of a table is called its schema. We need to understand a table's schema to effectively pull out the data we want. In this example, we'll investigate the full table that we fetched above.\n"]},{"cell_type":"code","metadata":{"id":"SJLu35YqHxsQ","colab_type":"code","colab":{}},"source":["# Print information on all the columns in the \"full\" table in the \"hacker_news\" dataset\n","table.schema"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XlydsbJcKdC6","colab_type":"text"},"source":["Each SchemaField tells us about a specific column (which we also refer to as a field). In order, the information is:\n","\n","    The name of the column\n","    The field type (or datatype) in the column\n","    The mode of the column ('NULLABLE' means that a column allows NULL values, and is the default)\n","    A description of the data in that column\n","\n","The first field has the SchemaField:\n","\n","SchemaField('by', 'string', 'NULLABLE', \"The username of the item's author.\",())\n","\n","This tells us:\n","\n","    the field (or column) is called by,\n","    the data in this field is strings,\n","    NULL values are allowed, and\n","    it contains the usernames corresponding to each item's author.\n","\n","We can use the list_rows() method to check just the first five lines of of the full table to make sure this is right. (Sometimes databases have outdated descriptions, so it's good to check.) This returns a BigQuery RowIterator object that can quickly be converted to a pandas DataFrame with the to_dataframe() method.\n"]},{"cell_type":"code","metadata":{"id":"I21UYApVKMhh","colab_type":"code","colab":{}},"source":["# Preview the first five lines of the \"full\" table\n","client.list_rows(table, max_results=5).to_dataframe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TLV-h3IELD7-","colab_type":"code","colab":{}},"source":["# Preview the first five entries in the \"by\" column of the \"full\" table\n","client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K638GCvzP1fx","colab_type":"text"},"source":["# SELECT ... FROM, Where\n","\n","\n","    specify the column you want after the word SELECT, and then\n","    specify the table after the word FROM\n","    \n","    If you want multiple columns, you can select them with a comma between the names (for all the columns use *)\n"]},{"cell_type":"code","metadata":{"id":"3FvR5CCXLPmX","colab_type":"code","colab":{}},"source":["query = '''\n","SELECT name\n","FROM 'project.database.table'\n","Where Animal = 'cat'\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HkZlERT9QAj4","colab_type":"text"},"source":["# Submitting the query to the dataset"]},{"cell_type":"code","metadata":{"id":"HHckXuziQGDh","colab_type":"code","colab":{}},"source":["# Create a \"Client\" object\n","client = bigquery.Client()\n","\n","# Set up the query\n","query_job = client.query(query)\n","\n","# API request : run the query, and return a pandas DataFrame\n","us_cities = query_job.to_dataframe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EUX_9f7JVHeC","colab_type":"text"},"source":["Now we've got a pandas DataFrame called us_cities, which we can use like any other DataFrame. "]},{"cell_type":"code","metadata":{"id":"oBFAg1tBVGbv","colab_type":"code","colab":{}},"source":["# What five cities have the most measurements?\n","us_cities.city.value_counts().head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RCjU9-RzVpOa","colab_type":"text"},"source":["# How much data a query will scan?"]},{"cell_type":"code","metadata":{"id":"ZTCiydYZVoXh","colab_type":"code","colab":{}},"source":["# Query to get the score column from every row where the type column has value \"job\"\n","query = \"\"\"\n","        SELECT score, title\n","        FROM `bigquery-public-data.hacker_news.full`\n","        WHERE type = \"job\" \n","        \"\"\"\n","\n","# Create a QueryJobConfig object to estimate size of query without running it\n","dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n","\n","# API request - dry run query to estimate costs\n","dry_run_query_job = client.query(query, job_config=dry_run_config)\n","\n","print(\"This query will process {} bytes.\".format(dry_run_query_job.total_bytes_processed))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ncBlGIzTV5e_","colab_type":"text"},"source":["# Specify a parameter when running the query to limit how much data you are willing to scan"]},{"cell_type":"code","metadata":{"id":"jHG-4fQDVz14","colab_type":"code","colab":{}},"source":["# Only run the query if it's less than 1 MB\n","ONE_MB = 1000*1000\n","safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)\n","\n","# Set up the query (will only run if it's less than 1 MB)\n","safe_query_job = client.query(query, job_config=safe_config)\n","\n","# API request - try to run the query, and return a pandas DataFrame\n","safe_query_job.to_dataframe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IiFcIHNaWJ_a","colab_type":"text"},"source":["In this case, the query was cancelled, because the limit of 1 MB was exceeded. However, we can increase the limit to run the query successfully!"]},{"cell_type":"code","metadata":{"id":"us2-TqtpWMK5","colab_type":"code","colab":{}},"source":["# Only run the query if it's less than 1 GB\n","ONE_GB = 1000*1000*1000\n","safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_GB)\n","\n","# Set up the query (will only run if it's less than 1 GB)\n","safe_query_job = client.query(query, job_config=safe_config)\n","\n","# API request - try to run the query, and return a pandas DataFrame\n","job_post_scores = safe_query_job.to_dataframe()\n","\n","# Print average score for job posts\n","job_post_scores.score.mean()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xulVKxX9l9yM","colab_type":"text"},"source":["# COUNT()"]},{"cell_type":"markdown","metadata":{"id":"25DrtaWSmB6A","colab_type":"text"},"source":["COUNT(), as you may have guessed from the name, returns a count of things. If you pass it the name of a column, it will return the number of entries in that column.\n","\n","For instance, if we SELECT the COUNT() of the ID column in the pets table, it will return 4, because there are 4 ID's in the table.\n","\n","COUNT() is an example of an aggregate function, which takes many values and returns one. (Other examples of aggregate functions include SUM(), AVG(), MIN(), and MAX().) As you'll notice in the picture above, aggregate functions introduce strange column names (like f0__). Later in this tutorial, you'll learn how to change the name to something more descriptive."]},{"cell_type":"code","metadata":{"id":"LFrSAUCRmAQ8","colab_type":"code","colab":{}},"source":["query = \"\"\"\n","SELECT COUNT(id)\n","FROM project.database.table\n","\"\"\"\n","\n","# aggregate functions : COUNT(), SUM(), AVG(), MIN(), MAX()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kiH372ykmLi8","colab_type":"text"},"source":["# GROUP BY"]},{"cell_type":"markdown","metadata":{"id":"hlHDtOVdmOQ3","colab_type":"text"},"source":["GROUP BY takes the name of one or more columns, and treats all rows with the same value in that column as a single group when you apply aggregate functions like COUNT().\n","\n","For example, say we want to know how many of each type of animal we have in the pets table. We can use GROUP BY to group together rows that have the same value in the Animal column, while using COUNT() to find out how many ID's we have in each group.\n","\n","It returns a table with three rows (one for each distinct animal). We can see that the pets table contains 1 rabbit, 1 dog, and 2 cats."]},{"cell_type":"code","metadata":{"id":"GRPUC1dRmtW_","colab_type":"code","colab":{}},"source":["query = \"\"\"\n","SELECT animal, COUNT(id)\n","FROM project.database.table\n","GROUP BY animal\n","\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RPd8ZtVXmRyi","colab_type":"text"},"source":["# GROUP BY HAVING"]},{"cell_type":"markdown","metadata":{"id":"6D3-nXiimVt1","colab_type":"text"},"source":["HAVING is used in combination with GROUP BY to ignore groups that don't meet certain criteria.\n","\n","So this query, for example, will only include groups that have more than one ID in them.\n","\n","Since only one group meets the specified criterion, the query will return a table with only one row."]},{"cell_type":"code","metadata":{"id":"sJ-RF7iYmyXI","colab_type":"code","colab":{}},"source":["query = \"\"\"\n","SELECT animal, COUNT(id)\n","FROM project.database.table\n","GROUP BY animal\n","HAVING COUNT(id)>1 \n","\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3HkezSeYnU7d","colab_type":"text"},"source":["# Aliasing and other improvements"]},{"cell_type":"markdown","metadata":{"id":"sw7Ob5-BnWzC","colab_type":"text"},"source":["A couple hints to make your queries even better:\n","\n","    The column resulting from COUNT(id) was called f0__. That's not a very descriptive name. You can change the name by adding AS NumPosts after you specify the aggregation. This is called aliasing, and it will be covered in more detail in an upcoming lesson.\n","    If you are ever unsure what to put inside the COUNT() function, you can do COUNT(1) to count the rows in each group. Most people find it especially readable, because we know it's not focusing on other columns. It also scans less data than if supplied column names (making it faster and using less of your data access quota).\n","\n","Using these tricks, we can rewrite our query:"]},{"cell_type":"code","metadata":{"id":"Ki9ivswwncir","colab_type":"code","colab":{}},"source":["# Improved version of earlier query, now with aliasing & improved readability\n","query_improved = \"\"\"\n","                 SELECT parent, COUNT(1) AS NumPosts\n","                 FROM `bigquery-public-data.hacker_news.comments`\n","                 GROUP BY parent\n","                 HAVING COUNT(1) > 10\n","                 \"\"\"\n","\n","safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n","query_job = client.query(query_improved, job_config=safe_config)\n","\n","# API request - run the query, and convert the results to a pandas DataFrame\n","improved_df = query_job.to_dataframe()\n","\n","# Print the first five rows of the DataFrame\n","improved_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kBpijAf_n7B4","colab_type":"text"},"source":["# Note on using GROUP BY"]},{"cell_type":"markdown","metadata":{"id":"RU0a8Qyan9gz","colab_type":"text"},"source":["Note that because it tells SQL how to apply aggregate functions (like COUNT()), it doesn't make sense to use GROUP BY without an aggregate function. Similarly, if you have any GROUP BY clause, then all variables must be passed to either a\n","\n","    GROUP BY command, or\n","    an aggregation function.\n","\n","Consider the query below:"]},{"cell_type":"code","metadata":{"id":"oXpQgSvin6g1","colab_type":"code","colab":{}},"source":["query_good = \"\"\"\n","             SELECT parent, COUNT(id)\n","             FROM `bigquery-public-data.hacker_news.comments`\n","             GROUP BY parent\n","             \"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jXbh3Ee4oDQZ","colab_type":"text"},"source":["Note that there are two variables: parent and id.\n","\n","    parent was passed to a GROUP BY command (in GROUP BY parent), and\n","    id was passed to an aggregate function (in COUNT(id)).\n","\n","And this query won't work, because the author column isn't passed to an aggregate function or a GROUP BY clause:\n"]},{"cell_type":"code","metadata":{"id":"LFEh9BvIoGgI","colab_type":"code","colab":{}},"source":["query_bad = \"\"\"\n","            SELECT author, parent, COUNT(id)\n","            FROM `bigquery-public-data.hacker_news.comments`\n","            GROUP BY parent\n","            \"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BSeNKc7aoMWh","colab_type":"text"},"source":["If make this error, you'll get the error message SELECT list expression references column (column's name) which is neither grouped nor aggregated at."]},{"cell_type":"markdown","metadata":{"id":"4zix1NbkBmEk","colab_type":"text"},"source":["# Order By"]},{"cell_type":"markdown","metadata":{"id":"thlQtgEABtuV","colab_type":"text"},"source":["ORDER BY is usually the last clause in your query, and it sorts the results returned by the rest of your query.\n","\n","Notice that the rows are not ordered by the ID column. We can quickly remedy this with the query below."]},{"cell_type":"code","metadata":{"id":"Yk64hi04BuqC","colab_type":"code","colab":{}},"source":["query = '''\n","SELECT ID, Name, Animal\n","FROM `bigquery-public-data.pet_records.pets`\n","ORDER BY ID \n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ohZQwii3CGgt","colab_type":"text"},"source":["You can reverse the order using the DESC argument (short for 'descending'). The next query sorts the table by the Animal column, where the values that are last in alphabetic order are returned first."]},{"cell_type":"code","metadata":{"id":"AStNgcVECIBw","colab_type":"code","colab":{}},"source":["query = '''\n","SELECT ID, Name, Animal\n","FROM `bigquery-public-data.pet_records.pets`\n","ORDER BY Animal DESC\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NaoTu3QICTVy","colab_type":"text"},"source":["# DATE and DATETIME\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3iJ6bR9iCZp_","colab_type":"text"},"source":["There are two ways that dates can be stored in BigQuery: as a DATE or as a DATETIME.\n","\n","The DATE format has the year first, then the month, and then the day. It looks like this:  YYYY-[M]M-[D]D\n","\n","YYYY: Four-digit year\n","[M]M: One or two digit month\n","[D]D: One or two digit day\n","\n","So 2019-01-10 is interpreted as January 10, 2019.\n","\n","The DATETIME format is like the date format ... but with time added at the end."]},{"cell_type":"markdown","metadata":{"id":"FtDonixdCzMU","colab_type":"text"},"source":["# Extract"]},{"cell_type":"markdown","metadata":{"id":"nchaD2x2C1-8","colab_type":"text"},"source":["To look at part of a date, like the year or the day : use EXTRACT"]},{"cell_type":"code","metadata":{"id":"dpdmjM_MCXaN","colab_type":"code","colab":{}},"source":["query = '''\n","SELECT Name, EXTRACT(DAY from Date) AS Day\n","FROM `bigquery-public-data.pet_records.pets_with_date`'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CNKPEMaGD3KB","colab_type":"text"},"source":["SQL is very smart about dates, and we can ask for information beyond just extracting part of the cell. For example, this query returns one column with just the week in the year (between 1 and 53) for each date in the Date column:"]},{"cell_type":"code","metadata":{"id":"XjWV8VJrD4mg","colab_type":"code","colab":{}},"source":["query = '''\n","SELECT Name, EXTRACT(WEEK from Date) AS Week\n","FROM `bigquery-public-data.pet_records.pets_with_date`'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zh64O2gsEBtd","colab_type":"text"},"source":["You can find all the functions you can use with dates in BigQuery in this documentation under \"Date and time functions\" : \n","\n","https://cloud.google.com/bigquery/docs/reference/legacy-sql#datetimefunctions"]},{"cell_type":"markdown","metadata":{"id":"GOFeyhsDEKo3","colab_type":"text"},"source":["## Example : determine how the number of accidents varies with the day of the week?\n","\n","The consecutive_number column contains a unique ID for each accident, and\n","The timestamp_of_crash column contains the date of the accident in DATETIME format\n","\n","we can:\n","EXTRACT the day of the week (as day_of_week in the query below) from the timestamp_of_crash column, and\n","GROUP BY the day of the week, before we COUNT the consecutive_number column to determine the number of accidents for each day of the week.\n","Then we sort the table with an ORDER BY clause, so the days with the most accidents are returned first.\n"]},{"cell_type":"code","metadata":{"id":"SgbvLjUyF1fJ","colab_type":"code","colab":{}},"source":["# Query to find out the number of accidents for each day of the week\n","query = \"\"\"\n","        SELECT COUNT(consecutive_number) AS num_accidents, \n","               EXTRACT(DAYOFWEEK FROM timestamp_of_crash) AS day_of_week\n","        FROM `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015`\n","        GROUP BY day_of_week\n","        ORDER BY num_accidents DESC\n","        \"\"\"\n","\n","# Set up the query (cancel the query if it would use too much of \n","# your quota, with the limit set to 1 GB)\n","safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**9)\n","query_job = client.query(query, job_config=safe_config)\n","\n","# API request - run the query, and convert the results to a pandas DataFrame\n","accidents_by_day = query_job.to_dataframe()\n","\n","# Print the DataFrame\n","accidents_by_day"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ysQIbpAuF_lC","colab_type":"text"},"source":["Notice that the data is sorted by the num_accidents column, where the days with more traffic accidents appear first.\n","\n","To map the numbers returned for the day_of_week column to the actual day, you might consult the BigQuery documentation on the DAYOFWEEK function. It says that it returns \"an integer between 1 (Sunday) and 7 (Saturday), inclusively\". So, in 2015, most fatal motor accidents in the US occured on Sunday and Saturday, while the fewest happened on Tuesday."]},{"cell_type":"markdown","metadata":{"id":"KyBbGEkKGCzy","colab_type":"text"},"source":["# Difference between WHERE and HAVING\n","\n","WHERE is used in any SELECT query, while HAVING clause is only used in SELECT queries containing aggregate function or group by clause. \n","\n","-> Both are used to specify filtering condition, but condition specified in WHERE clause is used while fetching data (rows) from table, and data which doesn't pass the condition will not be fetched into result set, on the other hand HAVING clause is later used to filter summarized data or grouped data. \n","\n","= In short if both WHERE and HAVING clause is used in a SELECT query with aggregate function or GROUP BY clause, it will execute before HAVING clause"]},{"cell_type":"markdown","metadata":{"id":"pz_yFgDON07Y","colab_type":"text"},"source":["# WITH .... AS"]},{"cell_type":"markdown","metadata":{"id":"X-CLSHP_N2-k","colab_type":"text"},"source":["With all that you've learned, your SQL queries are getting pretty long, which can make them hard understand (and debug).\n","\n","You are about to learn how to use AS and WITH to tidy up your queries and make them easier to read."]},{"cell_type":"markdown","metadata":{"id":"lV9WOa4cONrM","colab_type":"text"},"source":["On its own, AS is a convenient way to clean up the data returned by your query. It's even more powerful when combined with WITH in what's called a \"common table expression\".\n","\n","A common table expression (or CTE) is a temporary table that you return within your query. CTEs are helpful for splitting your queries into readable chunks, and you can write queries against them.\n","\n","For instance, you might want to use the pets table to ask questions about older animals in particular. So you can start by creating a CTE which only contains information about animals more than five years old like this:"]},{"cell_type":"code","metadata":{"id":"Ia2ZeTPxOX_6","colab_type":"code","colab":{}},"source":["query = \"\"\"\n","WITH Seniors AS \n","(\n","SELECT ID, Name\n","FROM 'bigquery-public-data.pet_records.pets'\n","WHERE Years_old > 5\n",")\n","SELECT ID\n","FROM Seniors\n","\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j_xuhe6SOp_G","colab_type":"text"},"source":["Also, it's important to note that CTEs only exist inside the query where you create them, and you can't reference them in later queries. So, any query that uses a CTE is always broken into two parts: (1) first, we create the CTE, and then (2) we write a query that uses the CTE."]},{"cell_type":"markdown","metadata":{"id":"Uz2mrODQPzb_","colab_type":"text"},"source":["## Example: How many Bitcoin transactions are made per month?\n","\n","We're going to use a CTE to find out how many Bitcoin transactions were made each day for the entire timespan of a bitcoin transaction dataset.\n","\n","We'll investigate the transactions table. "]},{"cell_type":"code","metadata":{"id":"oFO3jnvvP6-V","colab_type":"code","colab":{}},"source":["from google.cloud import bigquery\n","\n","# Create a \"Client\" object\n","client = bigquery.Client()\n","\n","# Construct a reference to the \"crypto_bitcoin\" dataset\n","dataset_ref = client.dataset(\"crypto_bitcoin\", project=\"bigquery-public-data\")\n","\n","# API request - fetch the dataset\n","dataset = client.get_dataset(dataset_ref)\n","\n","# Construct a reference to the \"transactions\" table\n","table_ref = dataset_ref.table(\"transactions\")\n","\n","# API request - fetch the table\n","table = client.get_table(table_ref)\n","\n","# Preview the first five lines of the \"transactions\" table\n","client.list_rows(table, max_results=5).to_dataframe()\n","\n","# Query to select the number of transactions per date, sorted by date\n","#block_timestamp column contains the date of each transaction in DATETIME format, we'll convert these into DATE\n","query_with_CTE = \"\"\" \n","                 WITH time AS \n","                 (\n","                     SELECT DATE(block_timestamp) AS trans_date\n","                     FROM `bigquery-public-data.crypto_bitcoin.transactions`\n","                 )\n","                 SELECT COUNT(1) AS transactions,\n","                        trans_date\n","                 FROM time\n","                 GROUP BY trans_date\n","                 ORDER BY trans_date\n","                 \"\"\"\n","\n","# Set up the query (cancel the query if it would use too much of \n","# your quota, with the limit set to 10 GB)\n","safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n","query_job = client.query(query_with_CTE, job_config=safe_config)\n","\n","# API request - run the query, and convert the results to a pandas DataFrame\n","transactions_by_date = query_job.to_dataframe()\n","\n","# Print the first five rows\n","transactions_by_date.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8JyWkaTQD_M","colab_type":"code","colab":{}},"source":["transactions_by_date.set_index('trans_date').plot() # plot the number of Bitcoin transactions per day over the whole timespan of the dataset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UnWl90v0grsq","colab_type":"text"},"source":["# Join"]},{"cell_type":"markdown","metadata":{"id":"n56sAjadh7Jl","colab_type":"text"},"source":["To get information that applies to a certain pet, we match the ID column in the pets table to the Pet_ID column in the owners table"]},{"cell_type":"code","metadata":{"id":"iAK4bBJPiF96","colab_type":"code","colab":{}},"source":["query = \"\"\"\n","SELECT p.Name AS Pet_Name, o.Name AS Owner_Name\n","FROM `bigquery-public-data.pet_records.pets` AS p\n","INNER JOIN `bigquery-public-data.pet_records.owner AS o\n","        ON p.ID = o.PET_ID \"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jN1h-H36jaag","colab_type":"text"},"source":["The type of JOIN we're using today is called an INNER JOIN. That means that a row will only be put in the final output table if the value in the columns you're using to combine them shows up in both the tables you're joining. "]},{"cell_type":"markdown","metadata":{"id":"AKPxX95XkhE5","colab_type":"text"},"source":["## Example: How many files are covered by each type of software license?\n","\n","We'll work with two tables in the database. The first table is the licenses table, which provides the name of each GitHub repo (in the repo_name column) and its corresponding license. \n","\n","The second table is the sample_files table, which provides, among other information, the GitHub repo that each file belongs to (in the repo_name column). \n","\n","Query that uses information in both tables to determine how many files are released in each license:"]},{"cell_type":"code","metadata":{"id":"G_PY8_XMk5R0","colab_type":"code","colab":{}},"source":["# Query to determine the number of files per license, sorted by number of files\n","query = \"\"\"\n","        SELECT L.license, COUNT(1) AS number_of_files\n","        FROM `bigquery-public-data.github_repos.sample_files` AS sf\n","        INNER JOIN `bigquery-public-data.github_repos.licenses` AS L \n","            ON sf.repo_name = L.repo_name\n","        GROUP BY L.license\n","        ORDER BY number_of_files DESC\n","        \"\"\"\n","\n","# Set up the query (cancel the query if it would use too much of \n","# your quota, with the limit set to 10 GB)\n","safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n","query_job = client.query(query, job_config=safe_config)\n","\n","# API request - run the query, and convert the results to a pandas DataFrame\n","file_count_by_license = query_job.to_dataframe()\n","\n","# Print the DataFrame\n","file_count_by_license"],"execution_count":0,"outputs":[]}]}