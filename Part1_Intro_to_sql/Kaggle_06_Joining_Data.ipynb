{"cells":[{"metadata":{},"cell_type":"markdown","source":"**[SQL Home Page](https://www.kaggle.com/learn/intro-to-sql)**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n[Stack Overflow](https://stackoverflow.com/) is a widely beloved question and answer site for technical questions. You'll probably use it yourself as you keep using SQL (or any programming language). \n\nTheir data is publicly available. What cool things do you think it would be useful for?\n\nHere's one idea:\nYou could set up a service that identifies the Stack Overflow users who have demonstrated expertise with a specific technology by answering related questions about it, so someone could hire those experts for in-depth help.\n\nIn this exercise, you'll write the SQL queries that might serve as the foundation for this type of service.\n\nAs usual, run the following cell to set up our feedback system before moving on."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex6 import *\nprint(\"Setup Complete\")","execution_count":1,"outputs":[{"output_type":"stream","text":"Using Kaggle's public dataset BigQuery integration.\nSetup Complete\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Run the next cell to fetch the `stackoverflow` dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"stackoverflow\" dataset\ndataset_ref = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","execution_count":2,"outputs":[{"output_type":"stream","text":"Using Kaggle's public dataset BigQuery integration.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Exercises\n\n### 1) Explore the data\n\nBefore writing queries or **JOIN** clauses, you'll want to see what tables are available. \n\n*Hint*: Tab completion is helpful whenever you can't remember a command. Type `client.` and then hit the tab key. Don't forget the period before hitting tab."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get a list of available tables \ntables = list(client.list_tables(dataset)) # Your code here\n\n# Print your answer\nlist_tables = [table.table_id for table in tables]\nprint(list_tables)\n\n# Check your answer\nq_1.check()","execution_count":9,"outputs":[{"output_type":"stream","text":"['badges', 'comments', 'post_history', 'post_links', 'posts_answers', 'posts_moderator_nomination', 'posts_orphaned_tag_wiki', 'posts_privilege_wiki', 'posts_questions', 'posts_tag_wiki', 'posts_tag_wiki_excerpt', 'posts_wiki_placeholder', 'stackoverflow_posts', 'tags', 'users', 'votes']\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 2, \"failureMessage\": \"Incorrect value for `list_of_tables`: `[<google.cloud.bigquery.table.TableListItem object at 0x7fe560d06f28>, <google.cloud.bigquery.table.TableListItem object at 0x7fe5623626d8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe5623626a0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b390>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b2e8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b6d8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b6a0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b5c0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b320>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b3c8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d255c0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d25358>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d250b8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560cde390>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560cde2b0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560cde358>]`\", \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 82, \"questionId\": \"1_ListSOTables\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Incorrect: Incorrect value for `list_of_tables`: `[<google.cloud.bigquery.table.TableListItem object at 0x7fe560d06f28>, <google.cloud.bigquery.table.TableListItem object at 0x7fe5623626d8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe5623626a0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b390>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b2e8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b6d8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b6a0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b5c0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b320>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b3c8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d255c0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d25358>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d250b8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560cde390>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560cde2b0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560cde358>]`","text/markdown":"<span style=\"color:#cc3333\">Incorrect:</span> Incorrect value for `list_of_tables`: `[<google.cloud.bigquery.table.TableListItem object at 0x7fe560d06f28>, <google.cloud.bigquery.table.TableListItem object at 0x7fe5623626d8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe5623626a0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b390>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b2e8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b6d8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b6a0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b5c0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b320>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d0b3c8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d255c0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d25358>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560d250b8>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560cde390>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560cde2b0>, <google.cloud.bigquery.table.TableListItem object at 0x7fe560cde358>]`"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For the solution, uncomment the line below."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_1.solution()","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 1, \"learnTutorialId\": 82, \"questionId\": \"1_ListSOTables\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\n# Get a list of available tables \ntables = list(client.list_tables(dataset))\nlist_of_tables = [table.table_id for table in tables] \n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\n# Get a list of available tables \ntables = list(client.list_tables(dataset))\nlist_of_tables = [table.table_id for table in tables] \n\n```"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 2) Review relevant tables\n\nIf you are interested in people who answer questions on a given topic, the `posts_answers` table is a natural place to look. Run the following cell, and look at the output."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Construct a reference to the \"posts_answers\" table\nanswers_table_ref = dataset_ref.table(\"posts_answers\")\n\n# API request - fetch the table\nanswers_table = client.get_table(answers_table_ref)\n\n# Preview the first five lines of the \"posts_answers\" table\nclient.list_rows(answers_table, max_results=5).to_dataframe()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"         id title                                               body  \\\n0  55832858  None  <p>There may be privacy description <em>(for S...   \n1  55832872  None  <p>How do I set the name of the button to the ...   \n2  55832876  None  <pre><code>go test -v -timeout 30s &lt;path_to...   \n3  55832878  None  <p>I suggest you create one custom pin represe...   \n4  55832879  None  <p>You have to use <a href=\"https://en.cpprefe...   \n\n  accepted_answer_id answer_count  comment_count community_owned_date  \\\n0               None         None              0                 None   \n1               None         None              3                 None   \n2               None         None              0                 None   \n3               None         None              0                 None   \n4               None         None              2                 None   \n\n                     creation_date favorite_count  \\\n0 2019-04-24 14:45:59.090000+00:00           None   \n1 2019-04-24 14:46:52.690000+00:00           None   \n2 2019-04-24 14:47:09.227000+00:00           None   \n3 2019-04-24 14:47:10.297000+00:00           None   \n4 2019-04-24 14:47:16.853000+00:00           None   \n\n                last_activity_date last_edit_date last_editor_display_name  \\\n0 2019-04-24 14:45:59.090000+00:00           None                     None   \n1 2019-04-24 14:46:52.690000+00:00           None                     None   \n2 2019-04-24 14:47:09.227000+00:00           None                     None   \n3 2019-04-24 14:47:10.297000+00:00           None                     None   \n4 2019-04-24 14:47:16.853000+00:00           None                     None   \n\n  last_editor_user_id owner_display_name  owner_user_id  parent_id  \\\n0                None               None        7266317    6004032   \n1                None               None        5873109   55832746   \n2                None               None        5713047   16935965   \n3                None               None        6001090   33622927   \n4                None               None       10765031   55831782   \n\n   post_type_id  score  tags view_count  \n0             2      0  None       None  \n1             2      0  None       None  \n2             2      0  None       None  \n3             2      0  None       None  \n4             2      0  None       None  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>body</th>\n      <th>accepted_answer_id</th>\n      <th>answer_count</th>\n      <th>comment_count</th>\n      <th>community_owned_date</th>\n      <th>creation_date</th>\n      <th>favorite_count</th>\n      <th>last_activity_date</th>\n      <th>last_edit_date</th>\n      <th>last_editor_display_name</th>\n      <th>last_editor_user_id</th>\n      <th>owner_display_name</th>\n      <th>owner_user_id</th>\n      <th>parent_id</th>\n      <th>post_type_id</th>\n      <th>score</th>\n      <th>tags</th>\n      <th>view_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55832858</td>\n      <td>None</td>\n      <td>&lt;p&gt;There may be privacy description &lt;em&gt;(for S...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2019-04-24 14:45:59.090000+00:00</td>\n      <td>None</td>\n      <td>2019-04-24 14:45:59.090000+00:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>7266317</td>\n      <td>6004032</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55832872</td>\n      <td>None</td>\n      <td>&lt;p&gt;How do I set the name of the button to the ...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>3</td>\n      <td>None</td>\n      <td>2019-04-24 14:46:52.690000+00:00</td>\n      <td>None</td>\n      <td>2019-04-24 14:46:52.690000+00:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>5873109</td>\n      <td>55832746</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55832876</td>\n      <td>None</td>\n      <td>&lt;pre&gt;&lt;code&gt;go test -v -timeout 30s &amp;lt;path_to...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2019-04-24 14:47:09.227000+00:00</td>\n      <td>None</td>\n      <td>2019-04-24 14:47:09.227000+00:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>5713047</td>\n      <td>16935965</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>55832878</td>\n      <td>None</td>\n      <td>&lt;p&gt;I suggest you create one custom pin represe...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2019-04-24 14:47:10.297000+00:00</td>\n      <td>None</td>\n      <td>2019-04-24 14:47:10.297000+00:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>6001090</td>\n      <td>33622927</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55832879</td>\n      <td>None</td>\n      <td>&lt;p&gt;You have to use &lt;a href=\"https://en.cpprefe...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2</td>\n      <td>None</td>\n      <td>2019-04-24 14:47:16.853000+00:00</td>\n      <td>None</td>\n      <td>2019-04-24 14:47:16.853000+00:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>10765031</td>\n      <td>55831782</td>\n      <td>2</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"It isn't clear yet how to find users who answered questions on any given topic. But `posts_answers` has a `parent_id` column. If you are familiar with the Stack Overflow site, you might figure out that the `parent_id` is the question each post is answering.\n\nLook at `posts_questions` using the cell below."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Construct a reference to the \"posts_questions\" table\nquestions_table_ref = dataset_ref.table(\"posts_questions\")\n\n# API request - fetch the table\nquestions_table = client.get_table(questions_table_ref)\n\n# Preview the first five lines of the \"posts_questions\" table\nclient.list_rows(questions_table, max_results=5).to_dataframe()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"         id                                              title  \\\n0  56412356  S3 Multipart upload with pause and resume func...   \n1  56318079                           Angular Nginx Docker 404   \n2  56136152               Switch structure control for OSC msg   \n3  56207713            AWS QuickSight - Smooth line graph/plot   \n4  56250259  I am not able to access kubernetes dash-board ...   \n\n                                                body accepted_answer_id  \\\n0  <p>I am trying to acheive s3 multipart upload ...               None   \n1  <p>Been driving myself nuts trying to figure t...               None   \n2  <p>I’m new to SC and the whole music programmi...               None   \n3  <p>do you know if ''''AWS QuickSight'''' has a...               None   \n4  <p>I have installed docker and kubernetes in m...               None   \n\n   answer_count  comment_count community_owned_date  \\\n0             0              0                 None   \n1             1              0                 None   \n2             0              0                 None   \n3             0              0                 None   \n4             0              0                 None   \n\n                     creation_date favorite_count  \\\n0 2019-06-02 05:09:24.723000+00:00           None   \n1 2019-05-26 23:14:43.403000+00:00           None   \n2 2019-05-14 18:05:32.077000+00:00           None   \n3 2019-05-19 12:15:57.697000+00:00           None   \n4 2019-05-22 06:03:36.240000+00:00           None   \n\n                last_activity_date last_edit_date last_editor_display_name  \\\n0 2019-06-02 05:09:24.723000+00:00           None                     None   \n1 2019-05-26 23:21:11.503000+00:00           None                     None   \n2 2019-05-14 18:05:32.077000+00:00           None                     None   \n3 2019-05-19 12:15:57.697000+00:00           None                     None   \n4 2019-05-22 06:03:36.240000+00:00           None                     None   \n\n  last_editor_user_id owner_display_name  owner_user_id parent_id  \\\n0                None               None        7225816      None   \n1                None               None        1058951      None   \n2                None               None        8880735      None   \n3                None               None       11036699      None   \n4                None               None        9493974      None   \n\n   post_type_id  score                                            tags  \\\n0             1      0                 <javascript><amazon-s3><stream>   \n1             1      0  <angular><docker><nginx><http-status-code-404>   \n2             1      0                                 <supercollider>   \n3             1      0                                        <amazon>   \n4             1      0                          <kubernetes-dashboard>   \n\n   view_count  \n0           1  \n1         257  \n2           2  \n3           2  \n4           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>body</th>\n      <th>accepted_answer_id</th>\n      <th>answer_count</th>\n      <th>comment_count</th>\n      <th>community_owned_date</th>\n      <th>creation_date</th>\n      <th>favorite_count</th>\n      <th>last_activity_date</th>\n      <th>last_edit_date</th>\n      <th>last_editor_display_name</th>\n      <th>last_editor_user_id</th>\n      <th>owner_display_name</th>\n      <th>owner_user_id</th>\n      <th>parent_id</th>\n      <th>post_type_id</th>\n      <th>score</th>\n      <th>tags</th>\n      <th>view_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56412356</td>\n      <td>S3 Multipart upload with pause and resume func...</td>\n      <td>&lt;p&gt;I am trying to acheive s3 multipart upload ...</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2019-06-02 05:09:24.723000+00:00</td>\n      <td>None</td>\n      <td>2019-06-02 05:09:24.723000+00:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>7225816</td>\n      <td>None</td>\n      <td>1</td>\n      <td>0</td>\n      <td>&lt;javascript&gt;&lt;amazon-s3&gt;&lt;stream&gt;</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56318079</td>\n      <td>Angular Nginx Docker 404</td>\n      <td>&lt;p&gt;Been driving myself nuts trying to figure t...</td>\n      <td>None</td>\n      <td>1</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2019-05-26 23:14:43.403000+00:00</td>\n      <td>None</td>\n      <td>2019-05-26 23:21:11.503000+00:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1058951</td>\n      <td>None</td>\n      <td>1</td>\n      <td>0</td>\n      <td>&lt;angular&gt;&lt;docker&gt;&lt;nginx&gt;&lt;http-status-code-404&gt;</td>\n      <td>257</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>56136152</td>\n      <td>Switch structure control for OSC msg</td>\n      <td>&lt;p&gt;I’m new to SC and the whole music programmi...</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2019-05-14 18:05:32.077000+00:00</td>\n      <td>None</td>\n      <td>2019-05-14 18:05:32.077000+00:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>8880735</td>\n      <td>None</td>\n      <td>1</td>\n      <td>0</td>\n      <td>&lt;supercollider&gt;</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56207713</td>\n      <td>AWS QuickSight - Smooth line graph/plot</td>\n      <td>&lt;p&gt;do you know if ''''AWS QuickSight'''' has a...</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2019-05-19 12:15:57.697000+00:00</td>\n      <td>None</td>\n      <td>2019-05-19 12:15:57.697000+00:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>11036699</td>\n      <td>None</td>\n      <td>1</td>\n      <td>0</td>\n      <td>&lt;amazon&gt;</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>56250259</td>\n      <td>I am not able to access kubernetes dash-board ...</td>\n      <td>&lt;p&gt;I have installed docker and kubernetes in m...</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2019-05-22 06:03:36.240000+00:00</td>\n      <td>None</td>\n      <td>2019-05-22 06:03:36.240000+00:00</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>9493974</td>\n      <td>None</td>\n      <td>1</td>\n      <td>0</td>\n      <td>&lt;kubernetes-dashboard&gt;</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Are there any fields that identify what topic or technology each question is about? If so, how could you find the IDs of users who answered questions about a specific topic?\n\nThink about it, and then check the solution by running the code in the next cell."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_2.solution()","execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 82, \"questionId\": \"2_HowToFindExperts\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n`posts_questions` has a column called `tags` which lists the topics/technologies each question is about.\n\n`posts_answers` has a column called `parent_id` which identifies the ID of the question each answer is responding to.\n`posts_answers` also has an `owner_user_id` column which specifies the ID of the user who answered the question.\n\nYou can join these two tables to:\n- determine the `tags` for each answer, and then\n- select the `owner_user_id` of the answers on the desired tag.\n\nThis is exactly what you will do over the next few questions.","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n`posts_questions` has a column called `tags` which lists the topics/technologies each question is about.\n\n`posts_answers` has a column called `parent_id` which identifies the ID of the question each answer is responding to.\n`posts_answers` also has an `owner_user_id` column which specifies the ID of the user who answered the question.\n\nYou can join these two tables to:\n- determine the `tags` for each answer, and then\n- select the `owner_user_id` of the answers on the desired tag.\n\nThis is exactly what you will do over the next few questions.\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 3) Selecting the right questions\n\nA lot of this data is text. \n\nWe'll explore one last technique in this course which you can apply to this text.\n\nA **WHERE** clause can limit your results to rows with certain text using the **LIKE** feature. For example, to select just the third row of the `pets` table from the tutorial, we could use the query in the picture below.\n\n![](https://i.imgur.com/RccsXBr.png) \n\nYou can also use `%` as a \"wildcard\" for any number of characters. So you can also get the third row with:\n\n```\nquery = \"\"\"\n        SELECT * \n        FROM `bigquery-public-data.pet_records.pets` \n        WHERE Name LIKE '%ipl%'\n        \"\"\"\n```\n\nTry this yourself. Write a query that selects the `id`, `title` and `owner_user_id` columns from the `posts_questions` table. \n- Restrict the results to rows that contain the word \"bigquery\" in the `tags` column. \n- Include rows where there is other text in addition to the word \"bigquery\" (e.g., if a row has a tag \"bigquery-sql\", your results should include that too)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code here\nquestions_query = \"\"\"\n                  SELECT ID, title, owner_user_id\n                  FROM `bigquery-public-data.stackoverflow.posts_questions`\n                  WHERE tags LIKE '%bigquery%'\n                  \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquestions_query_job = client.query(questions_query, job_config = safe_config) # Your code goes here\n\n# API request - run the query, and return a pandas DataFrame\nquestions_results = questions_query_job.to_dataframe() # Your code goes here\n\n# Preview results\nprint(questions_results.head())\n\n# Check your answer\nq_3.check()","execution_count":15,"outputs":[{"output_type":"stream","text":"         ID                                              title  owner_user_id\n0  56217818  BigQuery: How do DML operations affect storage...       189336.0\n1  56187040  Unable to setup custom schedules in Bigquery D...      4749660.0\n2  56223596  Is it possible to UNNEST an array in BigQuery ...      2696815.0\n3  56240285  Google Big Query Storage API Inconsistently Re...      1113712.0\n4  56264424        FLATTEN results using MAX value in BigQuery       260826.0\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 82, \"questionId\": \"3_SelectRightQuestions\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For a hint or the solution, uncomment the appropriate line below."},{"metadata":{},"cell_type":"markdown","source":"### 4) Your first join\nNow that you have a query to select questions on any given topic (in this case, you chose \"bigquery\"), you can find the answers to those questions with a **JOIN**.  \n\nWrite a query that returns the `id`, `body` and `owner_user_id` columns from the `posts_answers` table for answers to \"bigquery\"-related questions. \n- You should have one row in your results for each answer to a question that has \"bigquery\" in the tags.  \n- Remember you can get the tags for a question from the `tags` column in the `posts_questions` table.\n\nHere's a reminder of what a **JOIN** looked like in the tutorial:\n```\nquery = \"\"\"\n        SELECT p.Name AS Pet_Name, o.Name AS Owner_Name\n        FROM `bigquery-public-data.pet_records.pets` as p\n        INNER JOIN `bigquery-public-data.pet_records.owners` as o \n            ON p.ID = o.Pet_ID\n        \"\"\"\n```\n\nIt may be useful to scroll up and review the first several rows of the `posts_answers` and `posts_questions` tables.  "},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Your code here\nanswers_query = \"\"\"\n                SELECT a.id, a.body, a.owner_user_id\n                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n                INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                        ON q.id = a.parent_id\n                WHERE q.tags LIKE '%bigquery%'\n                \"\"\"\n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nanswers_query_job = client.query(answers_query, job_config = safe_config) # Your code goes here\n\n# API request - run the query, and return a pandas DataFrame\nanswers_results = answers_query_job.to_dataframe() # Your code goes here\n\n# Preview results\nprint(answers_results.head())\n\n# Check your answer\nq_4.check()","execution_count":24,"outputs":[{"output_type":"error","ename":"BadRequest","evalue":"400 GET https://dp.kaggle.net/bigquery/v2/projects/kaggle-161607/queries/fe41e2ba-4f52-4d6f-b0bd-6642f8b5c5bc?maxResults=0&location=US: Query exceeded limit for bytes billed: 10000000000. 22801285120 or higher required.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-227e96b09383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# API request - run the query, and return a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0manswers_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswers_query_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Your code goes here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Preview results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mimported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m         \"\"\"\n\u001b[0;32m-> 2927\u001b[0;31m         return self.result().to_dataframe(\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m             \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m   2857\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0mcomplete\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2858\u001b[0m         \"\"\"\n\u001b[0;32m-> 2859\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2860\u001b[0m         \u001b[0;31m# Return an iterator instead of returning the job.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;31m# TODO: modify PollingFuture so it can pass a retry argument to done().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mthe\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreached\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mcompletes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \"\"\"\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36m_blocking_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2831\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_blocking_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2832\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2833\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2835\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_RETRY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36m_blocking_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mretry_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_or_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRetryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise concurrent.futures.TimeoutError(\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             )\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36m_done_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_done_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m\"\"\"Check if the future is done and raise if it's not.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0m_OperationNotComplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mdone\u001b[0;34m(self, retry)\u001b[0m\n\u001b[1;32m   2818\u001b[0m                 \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2819\u001b[0m                 \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2820\u001b[0;31m                 \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2821\u001b[0m             )\n\u001b[1;32m   2822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_get_query_results\u001b[0;34m(self, job_id, retry, project, timeout_ms, location)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;31m# QueryJob.result()). So we don't need to poll here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         resource = self._call_api(\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         )\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_QueryResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_api_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_RETRY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             )\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/root/.local/lib/python3.6/site-packages/kaggle_gcp.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \"\"\"\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mForbidden\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             msg = (\"Permission denied using Kaggle's public BigQuery integration. \"\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBadRequest\u001b[0m: 400 GET https://dp.kaggle.net/bigquery/v2/projects/kaggle-161607/queries/fe41e2ba-4f52-4d6f-b0bd-6642f8b5c5bc?maxResults=0&location=US: Query exceeded limit for bytes billed: 10000000000. 22801285120 or higher required."]}]},{"metadata":{},"cell_type":"markdown","source":"For a hint or the solution, uncomment the appropriate line below."},{"metadata":{},"cell_type":"markdown","source":"### 5) Answer the question\nYou have the merge you need. But you want a list of users who have answered many questions... which requires more work beyond your previous result.\n\nWrite a new query that has a single row for each user who answered at least one question with a tag that includes the string \"bigquery\". Your results should have two columns:\n- `user_id` - contains the `owner_user_id` column from the `posts_answers` table\n- `number_of_answers` - contains the number of answers the user has written to \"bigquery\"-related questions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code here\nbigquery_experts_query = \"\"\"\n                SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n                INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                        ON q.id = a.parent_Id\n                WHERE q.tags LIKE '%bigquery%'\n                GROUP BY a.owner_user_id\n                \"\"\"\n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nbigquery_experts_query_job = client.query(bigquery_experts_query, job_config = safe_config) # Your code goes here\n\n# API request - run the query, and return a pandas DataFrame\nbigquery_experts_results = bigquery_experts_query_job.to_dataframe() # Your code goes here\n\n# Preview results\nprint(bigquery_experts_results.head())\n\n# Check your answer\nq_5.check()","execution_count":30,"outputs":[{"output_type":"stream","text":"     user_id  number_of_answers\n0  7813005.0                 25\n1   454137.0                  2\n2  9908251.0                  9\n3  5691525.0                 10\n4  3058302.0                  8\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 82, \"questionId\": \"5_BigQueryExperts\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 6) Building a more generally useful service\n\nHow could you convert what you've done to a general function a website could call on the backend to get experts on any topic?  \n\nThink about it and then check the solution below."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_6.solution()","execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 82, \"questionId\": \"6_GeneralizeExpertFinder\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\ndef expert_finder(topic, client):\n    '''\n    Returns a DataFrame with the user IDs who have written Stack Overflow answers on a topic.\n\n    Inputs:\n        topic: A string with the topic of interest\n        client: A Client object that specifies the connection to the Stack Overflow dataset\n\n    Outputs:\n        results: A DataFrame with columns for user_id and number_of_answers. Follows similar logic to bigquery_experts_results shown above.\n    '''\n    my_query = \"\"\"\n               SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n               FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n               INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                   ON q.id = a.parent_Id\n               WHERE q.tags like '%{topic}%'\n               GROUP BY a.owner_user_id\n               \"\"\"\n               \n    # Set up the query (a real service would have good error handling for \n    # queries that scan too much data)\n    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)      \n    my_query_job = client.query(my_query, job_config=safe_config)\n    \n    # API request - run the query, and return a pandas DataFrame\n    results = my_query_job.to_dataframe()\n\n    return results\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\ndef expert_finder(topic, client):\n    '''\n    Returns a DataFrame with the user IDs who have written Stack Overflow answers on a topic.\n\n    Inputs:\n        topic: A string with the topic of interest\n        client: A Client object that specifies the connection to the Stack Overflow dataset\n\n    Outputs:\n        results: A DataFrame with columns for user_id and number_of_answers. Follows similar logic to bigquery_experts_results shown above.\n    '''\n    my_query = \"\"\"\n               SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n               FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n               INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                   ON q.id = a.parent_Id\n               WHERE q.tags like '%{topic}%'\n               GROUP BY a.owner_user_id\n               \"\"\"\n               \n    # Set up the query (a real service would have good error handling for \n    # queries that scan too much data)\n    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)      \n    my_query_job = client.query(my_query, job_config=safe_config)\n    \n    # API request - run the query, and return a pandas DataFrame\n    results = my_query_job.to_dataframe()\n\n    return results\n\n```"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Congratulations!\n\nYou know all the key components to use BigQuery and SQL effectively. Your SQL skills are sufficient to unlock many of the world's largest datasets.\n\nWant to go play with your new powers?  Kaggle has BigQuery datasets available [here](https://www.kaggle.com/datasets?sortBy=hottest&group=public&page=1&pageSize=20&size=sizeAll&filetype=fileTypeBigQuery).\n\n# Feedback\n\nBring any questions or feedback to the [Learn Discussion Forum](https://www.kaggle.com/learn-forum)."},{"metadata":{},"cell_type":"markdown","source":"---\n**[SQL Home Page](https://www.kaggle.com/learn/intro-to-sql)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}