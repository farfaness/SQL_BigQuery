{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sql_BigQuery_Kaggle_course_part2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Q2dSu9yK5O1j","colab_type":"text"},"source":["# JOINS"]},{"cell_type":"markdown","metadata":{"id":"ZBAAxJKR5dRq","colab_type":"text"},"source":["To create a table containing all rows from the owners table, we use a LEFT JOIN. In this case, \"left\" refers to the table that appears before the JOIN in the query. (\"Right\" refers to the table that is after the JOIN.)"]},{"cell_type":"markdown","metadata":{"id":"pWvUCnv455CO","colab_type":"text"},"source":["![Texte alternatif…](https://i.imgur.com/tnOqw2S.png)"]},{"cell_type":"markdown","metadata":{"id":"zm1Z3vWe5-JN","colab_type":"text"},"source":["Replacing INNER JOIN in the query above with LEFT JOIN returns all rows where the two tables have matching entries, along with all of the rows in the left table (whether there is a match or not).\n","\n","If we instead use a RIGHT JOIN, we get the matching rows, along with all rows in the right table (whether there is a match or not).\n","\n","Finally, a FULL JOIN returns all rows from both tables. Note that in general, any row that does not have a match in both tables will have NULL entries for the missing values. You can see this in the image below."]},{"cell_type":"markdown","metadata":{"id":"aqh47tq96LR3","colab_type":"text"},"source":["![Texte alternatif…](https://i.imgur.com/1Dvmg8S.png)"]},{"cell_type":"markdown","metadata":{"id":"qS5Ez1cS6i2p","colab_type":"text"},"source":["# UNIONS"]},{"cell_type":"markdown","metadata":{"id":"9Se9xTPv6mM9","colab_type":"text"},"source":["As you've seen, JOINs horizontally combine results from different tables. If you instead would like to vertically concatenate columns, you can do so with a UNION. The example query below combines the Age columns from both tables."]},{"cell_type":"code","metadata":{"id":"wNzjp1MN4FvS","colab_type":"code","colab":{}},"source":["query = '''\n","SELECT Age\n","FROM bigquery-public-data.pet_records.pets\n","UNION ALL\n","SELECT Age \n","FROM bigquery-public-data.pet_records.owners'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3FA4uTuk7KLn","colab_type":"text"},"source":["We use UNION ALL to include duplicate values - you'll notice that 9 appears in both the owners table and the pets table, and shows up twice in the concatenated results. If you'd like to drop duplicate values, you need only change UNION ALL in the query to UNION DISTINCT."]},{"cell_type":"markdown","metadata":{"id":"-novGBbvhiJv","colab_type":"text"},"source":["# Analytic functions"]},{"cell_type":"markdown","metadata":{"id":"c0M4QsIRhkYA","colab_type":"text"},"source":["Too understand how to write analytic functions, we'll work with a small table containing data from two different people who are training for a race. The id column identifies each runner, the date column holds the day of the training session, and time shows the time (in minutes) that the runner dedicated to training. \n","\n","Say we'd like to calculate a moving average of the training times for each runner, where we always take the average of the current and previous training sessions. We can do this with the following query:"]},{"cell_type":"code","metadata":{"id":"PC_N6SgwiK-k","colab_type":"code","colab":{}},"source":["query = '''\n","SELECT *, AVG(time) OVER(\n","                          PARTITION BY id\n","                          ORDER BY date\n","                          ROWS BETWEEN 1 PRECEDING AND CURRENT ROW\n","                          ) AS avg_time\n","FROM `bigquery-public-data.runners.train_time'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FY4IzNg6i5eo","colab_type":"text"},"source":["Over = set of rows used in each calculation, with three optional parts\n","\n","\n","*   PARTITION BY : divide rows into groups\n","*   ORDER BY : ordering of each partition\n","*   window frame clause : set of row used for each calculation\n","\n","examples :  \n","* ROWS BETWEEN 1 PRECEDING AND CURRENT ROW\n","* ROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING (include the current row)\n","* ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING (all rows in the partition)\n","\n","for complete list see : https://cloud.google.com/bigquery/docs/reference/standard-sql/analytic-function-concepts"]},{"cell_type":"markdown","metadata":{"id":"1RChDAZhl2jB","colab_type":"text"},"source":["AVG() is a aggregate function, that can be replaced by :\n","\n","* MIN(), MAX()\n","* AVG(), SUM()\n","* COUNT()\n","\n","Navigations functions :\n","* FIRST_VALUE(), LAST_VALUE()\n","* LEAD(), LAG() : value on a subsequent (or preceding row)\n","\n","Numbering functions :\n","* ROW_NUMBER() - order in which rows appear in the input\n","* RANK() - All rows with same value receive same rank, next row receives rank value which increments by the number of rows with the previous rank value"]},{"cell_type":"markdown","metadata":{"id":"YF0Epeqpoe8j","colab_type":"text"},"source":["## Example"]},{"cell_type":"markdown","metadata":{"id":"4aFfNXOHoiS7","colab_type":"text"},"source":["We'll work with the San Francisco Open Data dataset. We begin by reviewing the first several rows of the bikeshare_trips table."]},{"cell_type":"code","metadata":{"id":"H4urTsnpnFNC","colab_type":"code","colab":{}},"source":["from google.cloud import bigquery\n","\n","# Create a \"Client\" object\n","client = bigquery.Client()\n","\n","# Construct a reference to the \"san_francisco\" dataset\n","dataset_ref = client.dataset(\"san_francisco\", project=\"bigquery-public-data\")\n","\n","# API request - fetch the dataset\n","dataset = client.get_dataset(dataset_ref)\n","\n","# Construct a reference to the \"bikeshare_trips\" table\n","table_ref = dataset_ref.table(\"bikeshare_trips\")\n","\n","# API request - fetch the table\n","table = client.get_table(table_ref)\n","\n","# Preview the first five lines of the table\n","client.list_rows(table, max_results=5).to_dataframe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OAmucp16oqC-","colab_type":"text"},"source":["Each row of the table corresponds to a different bike trip, and we can use an analytic function to calculate the cumulative number of trips for each date in 2015."]},{"cell_type":"code","metadata":{"id":"CYaJq2C3owJ2","colab_type":"code","colab":{}},"source":["# Query to count the (cumulative) number of trips per day\n","num_trips_query = \"\"\"\n","                  WITH trips_by_day AS\n","                  (\n","                  SELECT DATE(start_date) AS trip_date,\n","                      COUNT(*) as num_trips\n","                  FROM `bigquery-public-data.san_francisco.bikeshare_trips`\n","                  WHERE EXTRACT(YEAR FROM start_date) = 2015\n","                  GROUP BY trip_date\n","                  )\n","                  SELECT *,\n","                      SUM(num_trips) \n","                          OVER (\n","                               ORDER BY trip_date\n","                               ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n","                               ) AS cumulative_trips\n","                      FROM trips_by_day\n","                  \"\"\"\n","\n","# Run the query, and return a pandas DataFrame\n","num_trips_result = client.query(num_trips_query).result().to_dataframe()\n","num_trips_result.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W5YZ65Bzo1fw","colab_type":"text"},"source":["The query uses a common table expression (CTE) to first calculate the daily number of trips. Then, we use SUM() as an aggregate function.\n","\n","Since there is no PARTITION BY clause, the entire table is treated as a single partition.\n","The ORDER BY clause orders the rows by date, where earlier dates appear first.\n","By setting the window frame clause to ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW, we ensure that all rows up to and including the current date are used to calculate the (cumulative) sum. (Note: If you read the documentation, you'll see that this is the default behavior, and so the query would return the same result if we left out this window frame clause.)\n","\n","The next query tracks the stations where each bike began (in start_station_id) and ended (in end_station_id) the day on October 25, 2015."]},{"cell_type":"code","metadata":{"id":"_sscUQvuo57F","colab_type":"code","colab":{}},"source":["# Query to track beginning and ending stations on October 25, 2015, for each bike\n","start_end_query = \"\"\"\n","                  SELECT bike_number,\n","                      TIME(start_date) AS trip_time,\n","                      FIRST_VALUE(start_station_id)\n","                          OVER (\n","                               PARTITION BY bike_number\n","                               ORDER BY start_date\n","                               ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n","                               ) AS first_station_id,\n","                      LAST_VALUE(end_station_id)\n","                          OVER (\n","                               PARTITION BY bike_number\n","                               ORDER BY start_date\n","                               ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n","                               ) AS last_station_id,\n","                      start_station_id,\n","                      end_station_id\n","                  FROM `bigquery-public-data.san_francisco.bikeshare_trips`\n","                  WHERE DATE(start_date) = '2015-10-25' \n","                  \"\"\"\n","\n","# Run the query, and return a pandas DataFrame\n","start_end_result = client.query(start_end_query).result().to_dataframe()\n","start_end_result.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MxMYk8iTo9zd","colab_type":"text"},"source":["The query uses both FIRST_VALUE() and LAST_VALUE() as analytic functions.\n","\n","The PARTITION BY clause breaks the data into partitions based on the bike_number column. Since this column holds unique identifiers for the bikes, this ensures the calculations are performed separately for each bike.\n","\n","The ORDER BY clause puts the rows within each partition in chronological order.\n","Since the window frame clause is ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING, for each row, its entire partition is used to perform the calculation. (This ensures the calculated values for rows in the same partition are identical.)"]},{"cell_type":"markdown","metadata":{"id":"wPXz6zzbwI9V","colab_type":"text"},"source":["# Nested data"]},{"cell_type":"markdown","metadata":{"id":"nDVgZinbwKqF","colab_type":"text"},"source":["Consider a hypothetical dataset containing information about pets and their toys. We could organize this information in two different tables (a pets table and a toys table). The toys table could contain a \"Pet_ID\" column that could be used to match each toy to the pet that owns it.\n","\n","Another option in BigQuery is to organize all of the information in a single table, similar to the pets_and_toys table below."]},{"cell_type":"markdown","metadata":{"id":"2Haa0V5zwMMF","colab_type":"text"},"source":["![Texte alternatif…](https://i.imgur.com/wxuogYA.png)"]},{"cell_type":"markdown","metadata":{"id":"gNFqXjYTw2pH","colab_type":"text"},"source":["In this case, all of the information from the toys table is collapsed into a single column (the \"Toy\" column in the pets_and_toys table). We refer to the \"Toy\" column in the pets_and_toys table as a nested column, and say that the \"Name\" and \"Type\" fields are nested inside of it.\n","\n","Nested columns have type STRUCT (or type RECORD). This is reflected in the table schema below."]},{"cell_type":"markdown","metadata":{"id":"_C-iAjjnw5fC","colab_type":"text"},"source":["![Texte alternatif…](https://i.imgur.com/epXFXdb.png)"]},{"cell_type":"markdown","metadata":{"id":"WhU-UzsSxGah","colab_type":"text"},"source":["To query a column with nested data, we need to identify each field in the context of the column that contains it:\n","\n","* Toy.Name refers to the \"Name\" field in the \"Toy\" column, and\n","* Toy.Type refers to the \"Type\" field in the \"Toy\" column."]},{"cell_type":"markdown","metadata":{"id":"sTE1-NivxO7b","colab_type":"text"},"source":["# Repeated data"]},{"cell_type":"markdown","metadata":{"id":"R4nPilFexR3p","colab_type":"text"},"source":["Now consider the (more realistic!) case where each pet can have multiple toys. In this case, to collapse this information into a single table, we need to leverage a different datatype."]},{"cell_type":"markdown","metadata":{"id":"3j_K17NNxfrH","colab_type":"text"},"source":["![Texte alternatif…](https://i.imgur.com/S93FJTE.png)"]},{"cell_type":"markdown","metadata":{"id":"zKLkPqFWxpeg","colab_type":"text"},"source":["We say that the \"Toys\" column contains repeated data, because it permits more than one value for each row. This is reflected in the table schema below, where the mode of the \"Toys\" column appears as 'REPEATED'.\n","\n","![Texte alternatif…](https://i.imgur.com/KlrjpDM.png)"]},{"cell_type":"markdown","metadata":{"id":"XiiYX3XPx7iB","colab_type":"text"},"source":["Each entry in a repeated field is an ARRAY, or an ordered list of (zero or more) values with the same datatype. For instance, the entry in the \"Toys\" column for Moon the Dog is [Frisbee, Bone, Rope], which is an ARRAY with three values.\n","\n","When querying repeated data, we need to put the name of the column containing the repeated data inside an UNNEST() function.\n","This essentially flattens the repeated data (which is then appended to the right side of the table) so that we have one element on each row. For an illustration of this, check out the image below.\n","\n","![Texte alternatif…](https://i.imgur.com/8j4XK8f.png)"]},{"cell_type":"markdown","metadata":{"id":"z1QX9llBy4Qt","colab_type":"text"},"source":["# Nested and repeated data"]},{"cell_type":"markdown","metadata":{"id":"tqgGnxyIy70c","colab_type":"text"},"source":["Now, what if pets can have multiple toys, and we'd like to keep track of both the name and type of each toy? In this case, we can make the \"Toys\" column both nested and repeated.\n","\n","![Texte alternatif…](https://i.imgur.com/psKtza2.png)"]},{"cell_type":"markdown","metadata":{"id":"bpD6_Ny4zFFT","colab_type":"text"},"source":["In the more_pets_and_toys table above, \"Name\" and \"Type\" are both fields contained within the \"Toys\" STRUCT, and each entry in both \"Toys.Name\" and \"Toys.Type\" is an ARRAY\n","\n","![Texte alternatif…](https://i.imgur.com/fO5OymI.png)"]},{"cell_type":"markdown","metadata":{"id":"aBU79pUPzY75","colab_type":"text"},"source":["![Texte alternatif…](https://i.imgur.com/DiMCZaO.png)\n","\n","Since the \"Toys\" column is repeated, we flatten it with the UNNEST() function. And, since we give the flattened column an alias of t, we can refer to the \"Name\" and \"Type\" fields in the \"Toys\" column as t.Name and t.Type, respectively."]},{"cell_type":"markdown","metadata":{"id":"J_eFAZGW0H-f","colab_type":"text"},"source":["# Example"]},{"cell_type":"markdown","metadata":{"id":"IeubmbZ40JzM","colab_type":"text"},"source":["We'll work with the Google Analytics Sample dataset. It contains information tracking the behavior of visitors to the Google Merchandise store, an e-commerce website that sells Google branded items.\n","\n","We begin by printing the first few rows of the ga_sessions_20170801 table. (We have hidden the corresponding code. To take a peek, click on the \"Code\" button below.) This table tracks visits to the website on August 1, 2017."]},{"cell_type":"code","metadata":{"id":"EYk5HVnPwXxj","colab_type":"code","colab":{}},"source":["from google.cloud import bigquery\n","\n","# Create a \"Client\" object\n","client = bigquery.Client()\n","\n","# Construct a reference to the \"google_analytics_sample\" dataset\n","dataset_ref = client.dataset(\"google_analytics_sample\", project=\"bigquery-public-data\")\n","\n","# Construct a reference to the \"ga_sessions_20170801\" table\n","table_ref = dataset_ref.table(\"ga_sessions_20170801\")\n","\n","# API request - fetch the table\n","table = client.get_table(table_ref)\n","\n","# Preview the first five lines of the table\n","client.list_rows(table, max_results=5).to_dataframe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6uhuh0yS0VDA","colab_type":"text"},"source":["For a description of each field, refer to this data dictionary.\n","\n","The table has many nested fields, which you can verify by looking at either the data dictionary (hint: search for appearances of 'RECORD' on the page) or the table preview above.\n","\n","In our first query against this table, we'll work with the \"totals\" and \"device\" columns."]},{"cell_type":"code","metadata":{"id":"AKmBXYyU0Vtw","colab_type":"code","colab":{}},"source":["print(\"SCHEMA field for the 'totals' column:\\n\")\n","print(table.schema[5])\n","\n","print(\"\\nSCHEMA field for the 'device' column:\\n\")\n","print(table.schema[7])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L7brDZnL0Y2I","colab_type":"text"},"source":["We refer to the \"browser\" field (which is nested in the \"device\" column) and the \"transactions\" field (which is nested inside the \"totals\" column) as device.browser and totals.transactions in the query below:"]},{"cell_type":"code","metadata":{"id":"xfHJ-I_70dIJ","colab_type":"code","colab":{}},"source":["# Query to count the number of transactions per browser\n","query = \"\"\"\n","        SELECT device.browser AS device_browser,\n","            SUM(totals.transactions) as total_transactions\n","        FROM `bigquery-public-data.google_analytics_sample.ga_sessions_20170801`\n","        GROUP BY device_browser\n","        ORDER BY total_transactions DESC\n","        \"\"\"\n","\n","# Run the query, and return a pandas DataFrame\n","result = client.query(query).result().to_dataframe()\n","result.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dexMfOLc0gE7","colab_type":"text"},"source":["By storing the information in the \"device\" and \"totals\" columns as STRUCTs (as opposed to separate tables), we avoid expensive JOINs. This increases performance and keeps us from having to worry about JOIN keys (and which tables have the exact data we need).\n","\n","Now we'll work with the \"hits\" column as an example of data that is both nested and repeated. Since:\n","\n","\"hits\" is a STRUCT (contains nested data) and is repeated,\n","\"hitNumber\", \"page\", and \"type\" are all nested inside the \"hits\" column, and\n","\"pagePath\" is nested inside the \"page\" field,\n","we can query these fields with the following syntax:"]},{"cell_type":"code","metadata":{"id":"fzECLCnm0j8G","colab_type":"code","colab":{}},"source":["# Query to determine most popular landing point on the website\n","query = \"\"\"\n","        SELECT hits.page.pagePath as path,\n","            COUNT(hits.page.pagePath) as counts\n","        FROM `bigquery-public-data.google_analytics_sample.ga_sessions_20170801`, \n","            UNNEST(hits) as hits\n","        WHERE hits.type=\"PAGE\" and hits.hitNumber=1\n","        GROUP BY path\n","        ORDER BY counts DESC\n","        \"\"\"\n","\n","# Run the query, and return a pandas DataFrame\n","result = client.query(query).result().to_dataframe()\n","result.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mk5CFtv-0rlq","colab_type":"text"},"source":["In this case, most users land on the website through the \"/home\" page."]},{"cell_type":"markdown","metadata":{"id":"jLE_4_yz_WWp","colab_type":"text"},"source":["# Some useful functions"]},{"cell_type":"markdown","metadata":{"id":"i7Ts6pETAP32","colab_type":"text"},"source":["We will use two functions to compare the efficiency of different queries:\n","\n","* show_amount_of_data_scanned() : amount of data the query uses.\n","* show_time_to_run() : How long it takes for the query to execute."]},{"cell_type":"code","metadata":{"id":"ZsUX0AMiAjvC","colab_type":"code","colab":{}},"source":["from google.cloud import bigquery\n","from time import time\n","\n","client = bigquery.Client()\n","\n","def show_amount_of_data_scanned(query):\n","    # dry_run lets us see how much data the query uses without running it\n","    dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n","    query_job = client.query(query, job_config=dry_run_config)\n","    print('Data processed: {} GB'.format(round(query_job.total_bytes_processed / 10**9, 3)))\n","    \n","def show_time_to_run(query):\n","    time_config = bigquery.QueryJobConfig(use_query_cache=False)\n","    start = time()\n","    query_result = client.query(query, job_config=time_config).result()\n","    end = time()\n","    print('Time to run: {} seconds'.format(round(end-start, 3)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jDyot4aTDB5K","colab_type":"text"},"source":["# Strategy to reduce time to run and amount of data scanned"]},{"cell_type":"markdown","metadata":{"id":"RUfrN1a0DLYk","colab_type":"text"},"source":["Most of the JOINs that you have executed in this course have been 1:1 JOINs. In this case, each row in each table has at most one match in the other table. However, in general, most of JOINs are N:N JOIN (a group of rows in one table can match a group of rows in the other table). This type of JOIN produces a table with many more rows than either of the two (original) tables that are being JOINed.\n","\n","![Texte alternatif…](https://i.imgur.com/UsNZZoz.png)"]},{"cell_type":"code","metadata":{"id":"_3qlxBxzAjzK","colab_type":"code","colab":{}},"source":["#Both examples below count the number of distinct committers and the number of files in several GitHub repositories.\n","\n","big_join_query = \"\"\"\n","                 SELECT repo,\n","                     COUNT(DISTINCT c.committer.name) as num_committers,\n","                     COUNT(DISTINCT f.id) AS num_files\n","                 FROM `bigquery-public-data.github_repos.commits` AS c,\n","                     UNNEST(c.repo_name) AS repo\n","                 INNER JOIN `bigquery-public-data.github_repos.files` AS f\n","                     ON f.repo_name = repo\n","                 WHERE f.repo_name IN ( 'tensorflow/tensorflow', 'facebook/react', 'twbs/bootstrap', 'apple/swift', 'Microsoft/vscode', 'torvalds/linux')\n","                 GROUP BY repo\n","                 ORDER BY repo\n","                 \"\"\"\n","show_time_to_run(big_join_query)\n","\n","small_join_query = \"\"\"\n","                   WITH commits AS\n","                   (\n","                   SELECT COUNT(DISTINCT committer.name) AS num_committers, repo\n","                   FROM `bigquery-public-data.github_repos.commits`,\n","                       UNNEST(repo_name) as repo\n","                   WHERE repo IN ( 'tensorflow/tensorflow', 'facebook/react', 'twbs/bootstrap', 'apple/swift', 'Microsoft/vscode', 'torvalds/linux')\n","                   GROUP BY repo\n","                   ),\n","                   files AS \n","                   (\n","                   SELECT COUNT(DISTINCT id) AS num_files, repo_name as repo\n","                   FROM `bigquery-public-data.github_repos.files`\n","                   WHERE repo_name IN ( 'tensorflow/tensorflow', 'facebook/react', 'twbs/bootstrap', 'apple/swift', 'Microsoft/vscode', 'torvalds/linux')\n","                   GROUP BY repo\n","                   )\n","                   SELECT commits.repo, commits.num_committers, files.num_files\n","                   FROM commits \n","                   INNER JOIN files\n","                       ON commits.repo = files.repo\n","                   ORDER BY repo\n","                   \"\"\"\n","\n","show_time_to_run(small_join_query)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L8igaRY4EQy3","colab_type":"text"},"source":["* Time to run: 9.507 seconds\n","* Time to run: 3.151 seconds\n","\n","The first query has a large N:N JOIN. By rewriting the query to decrease the size of the JOIN, we see it runs much faster."]}]}